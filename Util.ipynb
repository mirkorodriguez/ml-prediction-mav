{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMdD+YNwSSHgTXtP0x66UWV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Machine Learning approach to analyze 3-Year prognostication for patients with brain arteriovenous malformation (bAVM) after stereotactic radiosurgery (SRS): a study for a small and heterogeneous group in Peru.\n","\n","> [Utils]\n","---"],"metadata":{"id":"ox3kIF0HDaXH"}},{"cell_type":"markdown","source":["## Main functions:"],"metadata":{"id":"DiMlgItNMWF_"}},{"cell_type":"code","source":["import joblib\n","\n","import pandas as pd\n","\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import GridSearchCV\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Functions\n","def trainAndGetBestModel(function, X, y, bal, the_metric, the_model_name, the_hyper_params, nfolds, random_seed, the_date_time, model_folder):\n","    balanced_prefix = \"bal_\" if bal==True else \"\"\n","    print('\\nTrain via Cross-Validation and Grid-Search for (%s) with Scoring (%s): \\n' % (the_model_name, the_metric))\n","    skf = StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=random_seed)\n","\n","    for i_fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n","        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n","        Y_train, Y_val = y.iloc[train_idx], y.iloc[val_idx]\n","        fold_id = str(i_fold + 1)\n","\n","        print('\\n\\nFold k: %s' % (fold_id))\n","        print('Training set size: %d' % len(Y_train))\n","        print('Validanting set size: %d' % len(Y_val))\n","\n","        # X_train_norm = X_train\n","        # X_val_norm = X_val\n","\n","        # Hyper-parameters \n","        param_grid = the_hyper_params\n","\n","        # Grid search\n","        print(\"\\nTraining Set: Looking for the best model ...\")\n","        clf = function\n","        internal_cv = StratifiedKFold(n_splits=nfolds)\n","        grid_cv = GridSearchCV(estimator=clf,\n","                              param_grid=param_grid,\n","                              cv=internal_cv,\n","                              scoring=the_metric.lower(),\n","                              verbose=0)\n","        grid_result = grid_cv.fit(X_train, Y_train)\n","        means = grid_result.cv_results_['mean_test_score']\n","        stds = grid_result.cv_results_['std_test_score']\n","        params = grid_result.cv_results_['params']\n","        for mean, stdev, param in zip(means, stds, params):\n","            print('\\t%s (train) | mean: %f, std: %f --> %r' % (the_metric.lower(), mean, stdev, param))\n","\n","        # Best model\n","        print('\\t> Best %s: %f for params %s' % (the_metric.lower(), grid_result.best_score_, grid_result.best_params_))    \n","        best_clf = grid_cv.best_estimator_\n","        print('\\t> Best model: %s' % best_clf)\n","        # Save best model\n","        model_file_name = \"\".join([balanced_prefix,the_model_name,'_',fold_id,'_',the_date_time,'.joblib'])\n","        joblib.dump(best_clf, \"/\".join([model_folder, 'cv', model_file_name]))\n","\n","        # Best model prediction (val)\n","        print(\"\\nValidating Set: Making Predictions ...\")\n","        Y_val_predicted = best_clf.predict(X_val)\n","        cm = confusion_matrix(Y_val, Y_val_predicted)\n","        getMetrics(cm, model_file_name, '')\n","        \n","\n","def crossValidation(X, y, bal, the_metric, the_model_name, nfolds, the_date_time, model_folder):\n","    balanced_prefix = \"bal_\" if bal==True else \"\"\n","    print('\\nCross-Validation for (%s) with Scoring (%s): \\n' % (the_model_name, the_metric))\n","    final_report_cv = []\n","    final_report_cv_title = ['ModelID', 'ModelName', 'Mean', 'Variance']\n","\n","    for i in range(nfolds):\n","      # Load model\n","      model_id = str(i + 1) \n","      model_name = balanced_prefix + the_model_name + '_%s_%s.joblib' % (model_id, the_date_time)\n","      model = joblib.load(\"/\".join([model_folder, 'cv', model_name]))\n","      scores = cross_val_score(estimator = model, X = X, y = y, scoring = the_metric, cv = nfolds)\n","      scores_mean = scores.mean() \n","      scores_variance = scores.std()\n","      final_report_cv.append([model_id, model_name, scores_mean, scores_variance])\n","      # print('\\t Model: %s %s > Mean: %f | Variance: %f' % (model_name, METRIC, scores_mean, scores_variance))\n","\n","    models = pd.DataFrame(final_report_cv, columns=final_report_cv_title)\n","    best_model = models.loc[[models['Mean'].idxmax()]]\n","    best_model_name = best_model['ModelName'].values[0]\n","    best_model_index = best_model['ModelID'].values[0]\n","    print(models)\n","    print('\\nBest model: ', best_model_name)\n","    return best_model\n","\n","def plot_roc_curve(fpr, tpr, auc_score, model_name):\n","    plt.figure()\n","    plt.plot(fpr, tpr, marker='.', label = \"\".join([model_name, \" (area = %0.2f)\"]) % auc_score)\n","    plt.plot([0, 1], [0, 1],'r--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","def getMetrics(cm, model_name, info):\n","    TN, FP, FN, TP = cm.ravel()\n","    # Accuracy\n","    accuracy = (TP+TN)/(TP+TN+FP+FN)\n","    # Sensitivity/Recall\n","    sensitivity = TP/(TP+FN)\n","    # Specificity\n","    specificity = TN/(TN+FP)\n","    # Positive Predictive Value (PPV)/ Precision\n","    PPV = TP/(TP + FP)\n","    # Negative Predictive Value (NPV)\n","    NPV = TN/(TN + FN)\n","    # BalancedAccuracy\n","    BA = (sensitivity + specificity)/2\n","    # F1Score\n","    F1 = 2*((PPV * sensitivity)/(PPV + sensitivity))\n","\n","    print(\"Accuracy:           \",\"({:.2%})\".format(accuracy))\n","    print(\"Sensitivity/Recall: \",\"({:.2%})\".format(sensitivity))\n","    print(\"Specificity:        \",\"({:.2%})\".format(specificity))\n","    print(\"PPV:                \",\"({:.2%})\".format(PPV))\n","    print(\"NPV:                \",\"({:.2%})\".format(NPV))\n","    print(\"Balanced Accuracy:  \",\"({:.2%})\".format(BA))\n","    print(\"F1 Score:           \",\"({:.2%})\".format(F1))\n","\n","    report_metrics = [model_name, info,\"%.4f\" % accuracy, \"%.4f\" % sensitivity, \"%.4f\" % specificity, \"%.4f\" % PPV, \"%.4f\" % NPV,\"%.4f\" % BA,\n","                      \"%.4f\" % F1, 'AUC', TN, FP, FN, TP]\n","    \n","    return report_metrics\n","\n","def saveFile(object_to_save, scaler_filename):\n","    joblib.dump(object_to_save, scaler_filename)\n","\n","def loadFile(scaler_filename):\n","    return joblib.load(scaler_filename)"],"metadata":{"id":"zo-FmArYMjL2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"t_ZDAQ-dCMGW"},"execution_count":null,"outputs":[]}]}